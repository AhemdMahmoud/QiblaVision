# -*- coding: utf-8 -*-
"""Compined_Code _Object_Pose.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D5E2EGB_FsjDd_SF1qcckqggtRGvzGIT
"""

!pip install ultralytics opencv-python-headless

! pip install mediapipe

from ultralytics import YOLO
import cv2
import mediapipe as mp
import numpy as np
from google.colab.patches import cv2_imshow

class ObjectAndPoseDetector:
    def __init__(self, yolo_model_path):
        # Initialize YOLO model
        self.yolo_model = YOLO(yolo_model_path)

        # Initialize MediaPipe Pose
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils

    def process_image(self, image_path):
        # Read image
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Could not read image at {image_path}")

        # Run YOLO detection
        yolo_results = self.yolo_model(image)[0]

        # Draw YOLO detections
        annotated_image = image.copy()
        boxes = yolo_results.boxes
        for box in boxes:
            # Get box coordinates
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            # Get confidence and class
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])

            # Draw bounding box
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            # Add label
            label = f"{yolo_results.names[class_id]} {confidence:.2f}"
            cv2.putText(annotated_image, label, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Convert to RGB for MediaPipe
        rgb_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)

        # Run pose detection
        pose_results = self.pose.process(rgb_image)

        # Draw pose landmarks if detected
        if pose_results.pose_landmarks:
            self.mp_drawing.draw_landmarks(
                annotated_image,
                pose_results.pose_landmarks,
                self.mp_pose.POSE_CONNECTIONS,
                self.mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),
                self.mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)
            )

        return annotated_image, yolo_results, pose_results

    def process_images(self, image_paths):
        """Process multiple images and yield results"""
        for image_path in image_paths:
            try:
                yield self.process_image(image_path)
            except Exception as e:
                print(f"Error processing {image_path}: {str(e)}")

    def __del__(self):
        # Clean up MediaPipe resources
        self.pose.close()

# Example usage
def main():
    # Initialize detector
    detector = ObjectAndPoseDetector("/content/best.pt")

    # List of images to process
    image_paths = [
        "/content/Annotation 2024-10-24 193701.png"
    ]

    # Process images
    for image_path in image_paths:
        # Process single image
        annotated_image, yolo_results, pose_results = detector.process_image(image_path)

        # Display or save results
        cv2_imshow(annotated_image)
        cv2.waitKey(0)

        # Save the annotated image
        output_path = f"output_{image_path.split('/')[-1]}"
        cv2.imwrite(output_path, annotated_image)

        # Print detection results if needed
        if pose_results.pose_landmarks:
            print(f"Pose detected in {image_path}")
        print(f"Objects detected: {len(yolo_results.boxes)}")

if __name__ == "__main__":
    main()





